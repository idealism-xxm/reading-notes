Kubernetes 可以监控 Pod ，并在监测到 CPU 使用率或其他度量数据增长时自动对它们扩容，同时，也可以自动新建更多节点。 `P443`

## Pod 的水平自动扩缩 `P444`

我们通过创建一个 HorizontalPodAutoscaler (HPA) 资源来实现自动扩缩，它会周期性检查 Pod 的度量数据，计算满足 HPA 资源所配置的目标数值所需的副本数量，进而调整目标资源（如： Deployment, ReplicaSet, StatefulSet 等）的 `replicas` 字段。 Pod 自动扩缩不适用于无法扩缩的资源，比如： DaemonSet 。 `P444`

### 了解自动扩缩的过程 `P444`

自动扩缩的过程可以分为三个步骤： `P444`

- 获取被扩缩资源对象所管理的所有 Pod 度量数据
- 计算使用度量数值到达（或接近）所指定目标数值所需的 Pod 数量
- 更新被扩缩资源的 `replicas` 字段

#### 获取 Pod 度量数据 `P444`

HPA 本身不负责采集 Pod 度量数据，而是从一系列的聚合 API (`metrics.k8s.io`, `custom.metrics.k8s.io` 和 `external.metrics.k8s.io`) 中获取度量数据。 `metrics.k8s.io` API 通常由 Metrics 服务器（需要额外启动）提供。

#### 计算所需的 Pod 数量 `P445`

一旦 HPA 获得了它所调整的资源所有 Pod 的全部度量数据，它便可以利用这些度量数据计算出所需的副本数量。

当 HPA 配置为只考虑单个度量数据时，计算所需副本数很简单，实际计算稍微复杂一点： `P445`

`目标副本数 = ceil(当前副本数 * (所有 Pod 的度量值之和 / HPA 配置的目标值))`

HPA 保证了度量数值不稳定、迅速抖动时不会导致系统抖动。 `P445`

当基于多个 Pod 度量值的自动扩缩时， HPA 单独计算每个度量的副本数，然后取最大值。 `P445`

![图 15.2 从两个度量计算副本数](img/chapter15/图%2015.2%20从两个度量计算副本数.png)

#### 更新被扩缩资源的副本数 `P446`

HPA 通过 Scale 子资源来修改被扩缩资源的 `replicas` 字段。

![图 15.3 HPA 只对 Scale 子资源进行更改](img/chapter15/图%2015.3%20HPA%20只对%20Scale%20子资源进行更改.png)

### 基于 CPU 使用率进行自动扩缩 `P447`

CPU 使用通常是不稳定的，所以需要把目标 CPU 使用率设置得远远低于 100% （一定不要超过 90% ），以预留充足空间给突发的流量洪峰。 `P446`

[14. 计算资源管理](14.%20计算资源管理.md) 中提到容器中的进程被保证能够使用该容器资源请求中所请求的 CPU 资源数量。对 HPA 来说， Pod 的 CPU 请求量与确定 Pod 的 CPU 使用率有关。因此，需要给被扩缩的 Pod 设置 CPU 请求量确保 HPA 能计算出 CPU 使用率，不管是直接设置还是通过 LimitRange 间接设置。 `P448`

#### 基于 CPU 使用率创建 HPA `P448`

我们可以使用如下 `deployment.yaml` 描述文件创建一个为所有 Pod 指定了 CPU 资源请求的 Deployment 资源。 `P448`

```yaml
# 遵循 apps/v1 版本的 Kubernetes API
apiVersion: apps/v1
# 资源类型为 Deployment
kind: Deployment
metadata:
  # Deployment 的名称
  name: kubia
spec:
  # 指定与标签选择器匹配的 pod 数目为 3
  replicas: 3
  # 指定 Deployment 操作对象
  selector:
    # 需要匹配以下指定的标签
    matchLabels:
      app: kubia
  # 启动 pod 使用的模版
  template:
    metadata:
      # 指定标签为 app=kubia
      labels:
        app: kubia
    spec:
      containers:
        # 容器的名称
        - name: kubia-node15
          # 创建容器所使用的镜像
          image: idealism/kubia:v1
          # 请求资源为 100 毫核 CPU
          resources:
            requests:
              cpu: 100m
            limits:
              cpu: 100m
```

**注意**：遇见使用 `kubectl top pods` 没有 Pod 的数据时不要慌张，自测发现只要 CPU 使用不到 1 毫核就不会显示，基本除了学习中使用的容器不会出现这种情况。以下是一天排查定位的艰苦过程：

- _经过一天不厌其烦地尝试（看遍了网上所有相关的问题，总是解决一个就出现其他问题），发现怎么都无法正常获取_
- _后来更新了 `minikube` 最新版，并且按照 `metrics-server` 的 [官方文档](https://github.com/kubernetes-sigs/metrics-server/tree/release-0.3#deployment) 重新部署了一次，发现问题依旧，不过已经可以正常获取节点和 `kube-system` 命名空间下 Pod 的数据了_
- _发现我们自己启动的 Pod 还是无法获取到，就只能开始自力更生，使用排除法慢慢排查了。首先怀疑是命名空间导致的问题，就在 `kube-system` 下面重新创建了一样的 Pod ，发现问题依旧，那么就只能是我们自己 Pod 的问题了_
- _接着运行 `kubectl logs -n kube-system metrics-server-c4b5b55c6-bvthx -f` 命令观察日志，发现只要运行 `kubectl top pods` 就会输出错误日志，拿着错误日志去源码中搜索到相应的片段，开始读源码追踪，发现错误日志之前基本只有获取相应的数据的代码，数据是另外写入的，那么要么是转换的时候丢了数据，要么是请求根本没有回传我们自己 Pod 的数据_
- _回看 [官方文档](https://github.com/kubernetes-sigs/metrics-server/tree/release-0.3#deployment) 发现可以给 `metrics-server` 的启动参数添加 `--v=10` 使其打印所有请求的请求体和响应体，添加后发现定时获取的数据确实没有我们自己 Pod 的数据，那么就只能是上层没有拿到数据_
- _此时开始思考两种 Pod 的区别，可是 `kube-system` 命名空间下的 Pod 没法 `exec` 进去查看详细信息，就部署了其他镜像的 Pod ，发现可以一直显示数据，并且发现原来那些 Pod 的数据不是不存在，而是时有时无_
- _此时观测所有有数据的 Pod 发现， CPU 使用最低是 1 毫核，所以猜测只要 CPU 使用不足 1 毫核，那么对应的数据就会被忽略，然后进入 Pod 执行了 shell 死循环语句，就发现该 Pod 的数据就一直常在了。然后进入 [Kubernetes 官方仓库](https://github.com/kubernetes/kubernetes/issues) 发现已经有类似的问题被提出了_

创建 Deployment 完成后，我们可以使用如下命令为其创建一个 HPA 。这个 HPA 将名为 `kubia` 的 Deployment 设置为扩缩目标，并且设置 Pod 的目标使用率为 30% ，指定了副本的最小和最大数量。 `P448`

`kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5`

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  ...
  # HPA 的名称，可以与 Deployment 的名称不一致
  name: kubia
  ...
spec:
  # 指定副本数的最大值和最小值
  minReplicas: 1
  maxReplicas: 5
  metrics:
  # 目标是让所有 Pod 的 CPU 资源的使用率趋近 30%
  - resource:
      name: cpu
      target:
        averageUtilization: 30
        type: Utilization
    type: Resource
  # HPA 作用的目标资源
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
status:
  ...
  # 由于前面所遇到的问题，此时 HPA 获取不到数据
  # 所以这里显示了 null ，并且前面还有相关的错误提示
  currentMetrics: null
  currentReplicas: 3
  desiredReplicas: 0
```

当我们在三个 Pod 中均执行死循环使其 CPU 跑满，过一段时间我们就可以发现 HPA 开始扩容 Pod 了，运行 `kubectl describe hpa` 就可以发现如下事件：

```shell script
...
Events:
  Type     Reason                        Age                 From                       Message
  ----     ------                        ----                ----                       -------
  Normal   SuccessfulRescale             32m                 horizontal-pod-autoscaler  New size: 5; reason: cpu resource utilization (percentage of request) above target
```

_不过由于前面提到的问题，计算使用的 Pod 数应该是有数据的 Pod 数，所以即使扩容后还会显示如下的 CPU 使用率 (`kubectl get hpa`) ，因为新启动的 Pod 没有被算入在内，并且即使我们停止所有死循环， CPU 使用率也不会改变，导致 Pod 无法缩容_

```shell script
NAME    REFERENCE          TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   100%/30%   1         5         5          28m
```

#### 了解扩缩操作的最大速率 `P452`

HPA 在单次扩容操作中可增加的副本数会受到限制，它最多使副本数翻倍。并且两次扩容操作之间的时间间隔也有限制，只有当 3 分钟内没有任何伸缩操作时才会触发扩容，而缩容操作的时间间隔是 5 分钟。 `P452`

### 基于内存使用进行自动扩缩 `P453`

基于内存的自动扩缩比基于 CPU 的困难很多。因为扩容之后原有的 Pod 需要有办法释放内存，这只能由应用完成，系统无法代劳。系统所能做的只有杀死并重启应用，如果应用重启后还是用了之前一样多的内存，那么 HPA 就会不断扩容直至达到设置的 Pod 数量上限。 `P453`

### 确定哪些度量适合用于自动扩缩 `P453`

不是所有度量都适合作为自动扩缩的基础，如果增加副本数不能导致被观测度量平均值的线性（或接近线性）下降，那么 HPA 就不能正常工作。 `P456`

## Pod 的垂直自动扩缩 `P456`

并非所有应用都能被水平扩缩，对他们而言只能使用垂直扩缩。 Kubernetes 目前支持使用 VPA 来实现垂直扩缩，不过其组件并非默认安装，需要手动进行安装。

## 集群节点的水平扩缩 `P457`

Kubernetes 支持在需要时立即自动从云服务提供者请求更多节点，该特性由 Cluster Autoscaler 执行。 `P457`

### Cluster Autoscaler 简介 `P457`

Cluster Autoscaler 负责在节点不足而无法调度某 Pod 到已有节点时自动部署新节点，它也会在节点长时间使用率低下的情况下下线节点。 `P457`

#### 从云端基础架构请求新节点 `P458`

如果一个 Pod 被创建之后， Scheduler 无法将其调度到任何一个已有节点，一个新节点就会被创建。 Cluster Autoscaler 会注意此类 Pod ，并请求云服务提供者启动一个新节点，并在此之前会检查新节点是否能容纳这个 Pod 。 `P458`

云服务提供者通常把相同规格（或者有相同特性）的节点聚合成组，因此请求新节点时还需要指明节点类型。 `P458`

Cluster Autoscaler 通过检查可用的节点分组来确定是否有至少一种节点类型能容纳未被调度的 Pod 。如果存在多个满足条件的节点分组， Cluster Autoscaler 就会挑选一个最合适的分组增加大小，让云服务提供商在分组中增加一个节点。新节点启动后，其上运行的 Kubelet 就会联系 API 服务器，创建一个 Nod 资源以注册该节点，然后成为集群的一部分，就可以调度 Pod 于其上了。 `P458`

![图 15.5 Cluster Autoscaler 触发集群扩容](img/chapter15/图%2015.5%20Cluster%20Autoscaler%20触发集群扩容.png)

#### 归还节点 `P459`

当节点利用率不足， Cluster Autoscaler 也需要能够减少节点的数量。如果节点有系统 Pod 在运行，那么该即诶单就不会被归还，对非托管 Pod 以及有本地存储的 Pod 也是如此，否则就会造成这些 Pod 提供的服务终端。即只有当 Cluster Autoscaler 知道节点上运行的 Pod 能够重新调度到其他节点时，该节点才会被归还。 `P459`

当一个节点被选中下线，它首先会被标记为不可调度，随后运行其上的 Pod 将被疏散至其他节点。 `P459`

节点也可以手动被标记为不可调度并排空： `P459`

- `kubectl cordon <node>`: 标记节点为不可调度，但对其上的 Pod 不做任何事
- `kubectl drain <node>`: 标记节点为不可调度，随后疏散其上所有 Pod

以上两种情况都可以使用 `kubectl uncordon <node>` 接触节点的不可调度状态。 `P459`

**注意**： Cluster Autoscaler 将它的状态发布到 `kube-system` 命名空间的 `cluster-autoscaler-status` ConfigMap 上。 `P460`

### 限制集群缩容时的服务干扰 `P460`

如果一个节点发生非预期故障，你不可能阻止其上的 Pod 变为不可用。但如果一个节点被 Cluster Autoscaler 或者手动下线，可以用一个特性来确保下线操作不会干扰这个节点上 Pod 所提供的服务。 `P460`

Kubernetes 可以指定下线等操作时需要保持的最少 Pod 数量，我们可以通过创建一个 PodDisruptionBudget 资源的方式来达到这一目的。 `P461`

`kubectl create pdb kubia-pdb --selector=app=kubia --min-available=3`: 确保具有 `app=kubia` 标签的 Pod 至少有 3 个实例在运行 `P461`

也可以设置一个百分比，例如可以指定 60% 带 `app=kubia` 标签的 Pod 应当时刻保持运行。 `P461`

只要 PDB 资源存在，那么 Cluster Autoscaler 与 `kubectl drain` 命令都会遵循它；如果疏散一个带 `app=kubia` 标签的 Pod 会导致它们的总数小于 3 ，那么这个操作就永远不会被执行。 `P461`
