## 集中一切资源 `P486`

![图 17.1 一个典型应用中的资源](img/chapter17/图%2017.1%20一个典型应用中的资源.png)

上图显示了一个典型应用中所使用的各个 Kubernetes 组件。 `P486`

## 了解 Pod 的生命周期 `P487`

### 应用必须预料到会被结束或者重新调度 `P487`

应用可以频繁地进行自动迁移而无须人工介入，也就是说没有人会对应用进行配置并确保它们在迁移之后能正常运行，因此应用开发者必须允许应用可以被相对频繁地迁移。 `P487`

#### 预料到本地 IP 和主机名会发生变化 `P488`

当一个 Pod 被结束并在其他地方运行之后，它就会拥有一新的 IP 地址、名称和主机名，大部分无状态应用可以处理这种场景。有状态应用可以通过一个 StatefulSet ([10. StatefulSet: 部署有状态的多副本应用](10.%20StatefulSet%3A%20部署有状态的多副本应用.md) 中介绍过) 来运行， StatefulSet 会保证将应用调度到新的节点并启动后，应用可以看到和之前一样的主机名和持久化状态。当然 Pod 的 IP 还是会变化，应用必须能够应对这种变化，因此一个集群应用中不应该依赖成员的 IP 地址来构建彼此的关系，可以使用主机名来构建关系。 `P488`

#### 预料到写入磁盘的数据会消失 `P488`

如果没有将持久化的存储挂载到应用的数据写入路径，那么应用写入的数据在启动后会丢失。无论是 Pod 被重新调度，还是单个容器被重启，容器都是全新的， Kubelet 不会一个容器运行多次，而是会重新创建一个容器。 `P488`

![图 17.2 写入到容器文件系统的文件在容器重启之后会丢失](img/chapter17/图%2017.2%20写入到容器文件系统的文件在容器重启之后会丢失.png)

我们可以使用存储卷来持久化数据，也可以用存储卷跨容器存储数据（[06. 卷：将磁盘挂载到容器](06.%20卷：将磁盘挂载到容器.md) 介绍过该用法）。存储卷持久化数据是把双刃剑，需要仔细思考是否使用，如果容器是由于数据损坏而奔溃，那么新创建的容器仍旧会奔溃，导致一个持续性的循环奔溃 (`CrashLoopBackOff`) 。 `P489`

![图 17.3 使用存储卷来跨容器持久化数据](img/chapter17/图%2017.3%20使用存储卷来跨容器持久化数据.png)

### 重新调度死亡的 Pod 或者部分死亡的 Pod `P490`

如果一个 Pod 的容器一直处于奔溃状态， Kubelet 将会一直不停地重启它们。每次重启的时间间隔会以指数级增加，直到达到 5 分钟。在容器处于奔溃重启期间，没有正常运行的进程，它无法提供相应的服务。 `P490`

![图 17.4 ReplicaSet 控制器没有重新调度死亡的 Pod](img/chapter17/图%2017.4%20ReplicaSet%20控制器没有重新调度死亡的%20Pod.png)

当容器处于奔溃重启的状态时， Pod 不会被自动移除或者重新调度，因为 ReplicaSet 等本身并不关心 Pod 是否处于死亡状态，它只关心 Pod 数量是否匹配期望的副本数。 `P490`

在重启间隔期间， Kubernetes 期望奔溃的底层原因会被解决。这个机制依据的基本原理就是将 Pod 重新调度到其他节点通常不会解决奔溃的问题，因为应用运行在容器的内部，所有节点理论上应该都是相同的。 `P491`

### 以固定顺序启动 Pod `P491`

#### 了解 Pod 是如何启动的 `P491`

Kubernetes API 服务器是按照 YAML/JSON 文件中定义的对象顺序来进行处理的，但仅仅意味着它们在被写入到 etcd 的时候是有序的。无法确保 Pod 会按照那个顺序启动。 `P491`

我们可以通过阻止一个主容器的启动，直到它的前置条件被满足。这个是通过在 Pod 中包含一个叫作 `init` 的容器来实现的。 `P492`

#### `init` 容器介绍 `P492`

除了常规的容器， Pod 还可以包括 `init` 容器，它们可以用来初始化 Pod ，这通常意味着向容器的存储卷写入数据，然后将这个存储卷挂载到主容器中。 `P492`

一个 Pod 可以拥有任意数量的 `init` 容器。它们是顺序执行的，并且仅当最后一个 `init` 容器执行完毕才会去启动主容器。 `P492`

#### 将 `init` 容器加入 Pod `P492`

[07. ConfigMap 和 Secret: 配置应用程序](07.%20ConfigMap%20和%20Secret%3A%20配置应用程序.md) 介绍了能够返回给客户端一个人生格言作为响应的 Web 服务。现在假设有一个叫作 `fortune-client` 的 Pod ，它的主容器需要依赖 `fortune` 服务先启动并且运行之后才能启动。那么可以给 `fortune-client` 的 Pod 添加一个 `init` 容器，这个容器主要不停请求 `fortune` 服务，直至被响应。当我们 `P492`

`init` 容器可以在 `Pod.spec.initContainers` 中定义，我们可以使用如下 `fortune-client.yaml` 描述文件创建一个有 `init` 容器的 Pod 。 `P492`

```yaml
# 遵循 v1 版本的 Kubernetes API
apiVersion: v1
# 资源类型为 Pod
kind: Pod
metadata:
  # Pod 的名称
  name: fortune-client
spec:
  # init 容器列表
  initContainers:
    # 第一个 init 容器的名称
    - name: init
      image: busybox
      # 该 init 容器运行一个循环，不停请求 fortune 服务，直至 fortune 服务启动
      command:
        - sh
        - -c
        - 'while true; do echo "Waiting for fortune service to come up..."; wget http://fortune -q -T 1 -O /dev/null >/dev/null 2>/dev/null && break; sleep 1; done; echo "Service is up! Starting main container."'
  # 主容器列表
  containers:
    - image: busybox
      name: main
      # 该主容器每 10 秒中请求 fortune 服务，并输出响应
      command:
        - sh
        - -c
        - 'echo "Main container started. Reading fortune very 10 seconds."; while true; do echo "-------------"; wget -q -O - http://fortune; sleep 10; done'
```

创建 Pod 后，我们使用 `kubectl get pods` 可以发现刚刚创建的 Pod 一直处于 `Init` 状态，表明其正在等待 `init` 容器执行。然后使用 `kubectl logs fortune-client -c init -f` ，我么可以发现一直在打印等待 `fortune` 服务启动的日志。当我们部署的 `fortune` 服务和响应的 Pod 启动后， `fortune-client` 的主容器才会运行。 `P493`

#### 处理 Pod 内部依赖的最佳实践 `P493`

我们现在已经知道如何通过 `init` 容器让主容器在前置条件被满足后再启动，但更佳的情况是构建一个不需要它所依赖的服务都准备好才能启动的应用。毕竟这些服务在后面也有可能下线，但这个时候应用已经在运行中了。 `P493`

如果一个应用在其中一个依赖缺失的情况下无法工作，那么它需要通过它的就绪探测器来通知这个情况，这样 Kubernetes 也会知道这个应用没有准备好。 `P493`

- 就绪探测器探测失败会阻止应用成为一个服务端点
- Deployment 在滚动升级的时候会使用就绪探测器，可以避免错误版本的出现

### 增加生命周期钩子 `P493`

Pod 允许定义两种类型类型的生命周期钩子：`postStart` 和 `preStop` 。 `init` 容器是应用到整个 Pod ，而生命周期的钩子是基于每个容器来指定的，分别是在容器启动后和停止前执行。 `P493`

生命周期钩子与存活探测器和就绪探测器的相似之处： `P493`

- 在容器内部执行一个命令
- 向一个 URL 发送 HTTP GET 请求

#### 使用 `postStart` 钩子 `P494`

`postStart` 钩子是在容器的主进程启动后立即执行的。可以用它在应用启动时做一些额外的工作。 `postStart` 钩子可以在不改动应用的情况下运行一些额外的命令，这些命令可能包括向外部监听器发送应用已启动的信号，或者初始化应用以使得应用能够顺利运行。 `P494`

`postStart` 钩子和主进程是并行执行的，它通过两种方式来影响容器： `P494`

- 在钩子执行完毕之前，容器会一直停留在 `Waiting` 状态，其原因是 `ContainerCreating` 。因此 Pod 的状态会是 `Pending` 而非 `Running`
- 如果钩子运行失败或者返回了非零的状态码，主容器会被杀死

我们可以使用如下 `post-start-hook.yaml` 描述文件创建一个有 `postStart` 钩子的 Pod 。 `P495`

```yaml
# 遵循 v1 版本的 Kubernetes API
apiVersion: v1
# 资源类型为 Pod
kind: Pod
metadata:
  # Pod 的名称
  name: pod-with-poststart-hook
spec:
  containers:
    - image: idealism/kubia
      name: kubia
      lifecycle:
        # postStart 钩子是在容器启动时执行的
        postStart:
          exec:
            command:
              - sh
              - -c
              - "echo 'hook will fail with exit code 15'; sleep 5 ; exit 15"
```

如果钩子程序启动的进程将日志输出到标准输出终端，如果钩子程序运行成功，那么将无法看到日志。如果钩子程序失败了，你会在 Pod 事件中看到一个 `FailedPostStartHook` 的报警，其对应的信息中会包含控制台的输出信息，如下所示： `P495`

```shell script
Events:
  Type     Reason               Age   From               Message
  ----     ------               ----  ----               -------
  ...
  Warning  FailedPostStartHook  1s    kubelet            Exec lifecycle hook ([sh -c echo 'hook will fail with exit code 15'; sleep 5 ; exit 15]) for Container "kubia" in Pod "pod-with-poststart-hook_default(4dcd13e9-3862-44aa-ae1a-05a21c094bd9)" failed - error: command 'sh -c echo 'hook will fail with exit code 15'; sleep 5 ; exit 15' exited with 15: , message: "hook will fail with exit code 15\n"
  ...
```

如果需要获取到钩子执行期间的日志，可以给容器挂载一个 `emptyDir` 卷，并让钩子程序向这个存储卷写入内容，这样在只要 Pod 存在就可以看到日志内容。 `P495`

#### 使用 `preStop` 钩子 `P495`

当一个容器需要终止运行时， Kubelet 在配置了 `preStop` 钩子的时候就会执行这个钩子，并且仅在执行完钩子程序后才会向容器进程发送 `SIGTERM` 信号。 `P495`

我们可以使用如下代码片段为 Pod 添加一个 `preStop` 钩子：

```yaml
lifecycle:
  preStop:
    # 该 preStop 钩子执行一个 HTTP GET 请求
    httpGet:
      # 这个请求发送到 http://POD_IP:8080/shutdown
      port: 8080
      path: shutdown
```

`httpGet` 下还可设置 `schema` (`HTTP`/`HTTPS`) 、 `host` 和 `httpHeaders` 。默认情况下， `host` 的值是 Pod 的 IP 地址。确保请求不会发送到 `localhost` ，因为它表示节点的地址，而非 Pod 的地址。 `P496`

无论 `preStop` 钩子执行是否成功，容器都会被终止。如果钩子执行失败， Pod 的事件中会有一个 `FailedPreStopHook` 的报警。 `P496`

**提示**：如果 `preStop` 钩子的成功执行对系统的行为很重要，请确认钩子是否执行成功。 `P496`

#### 应用没有收到 `SIGTERM` 信号 `P496`

应用没有收到信号的原因是因为容器内部信号没有传递给用用的进程。如果容器的镜像配置是通过执行一个 shell 进程，然后在 shell 进程内部执行应用进程，那么这个信号就会被这个 shell 吃掉，不会传递给子进程。 `P496`

有两种方式可以让应用收到 `SIGTERM` 信号： `P497`

- 在作为主进程执行的 shell 进程内处理信号，并把它传递给应用进程
- 直接运行应用的二进制文件，以 `exec` 的形式启动二进制文件： `ENTRYPOINT ["/mybinary"]` （[07. ConfigMap 和 Secret: 配置应用程序](07.%20ConfigMap%20和%20Secret%3A%20配置应用程序.md) 中介绍过 `ENTRYPOINT`/`CMD` 以及 shell / exec 形式的区别）

### 了解 Pod 的关闭 `P497`

Pod 的关闭是通过 API 服务器删除 Pod 的对象来触发的。当收到 HTTP DELETE 请求后， PAI 服务器还没有删除 Pod 对象，而是给 Pod 设置一个 `deletionTimestamp` 值。拥有 `deletionTimestamp` 的 Pod 就开始停止了。 `P497`

当 Kubelet 意识到需要终止 Pod 的时候，它开始终止 Pod 中的每个容器。 Kubelet 会给每个容器一定的时间来优雅地停止，这个时间通过 `Pod.spec.terminationGracePeriodSeconds` 字段设置，默认是 30s 。在终止进程开始之后，计时器开始计时，按照顺序执行以下事件： `P497`

1. 执行 `preStop` 钩子（如果配置了的话），然后等待它执行完毕
2. 向容器的主进程发送 `SIGTERM` 信号
3. 等待容器优雅地关闭或者等待超时
4. 如果容器主进程没有优雅地关闭，使用 `SIGKILL` 信号强制终止进程

![图 17.5 容器停止顺序](img/chapter17/图%2017.5%20容器停止顺序.png)

#### 指定终止宽限期 `P498`

**提示**：应该将终止宽限期设置得足够长，让容器进程有足够的时间完成清理工作。 `P498`

在删除 Pod 的时候，可以通过 `--grace-period=5` 参数覆盖终止宽限期。如果使用 `kubectl delete pod mypod --grace-period=0 --force` 可以立刻删除 Pod 资源。 `P498`

#### 在应用中合理地处理容器关闭操作 `P499`

应用应该通过启动关闭流程来响应 `SIGTERM` 信号，并且在流程结束后终止运行。除了处理 `SIGTERM` 信号，应用还可以通过 `preStop` 钩子来接收关闭通知。 `P499`

## 确保所有的客户端请求都得到了妥善处理 `P500`

Kubernetes 没有避免 Pod 在启动或者关闭的过程中出现连接断开的情况，应用需要遵循一些规则来避免遇到连接断开的情况。 `P500`

### 在 Pod 启动时避免客户端连接断开 `P500`

[05. 服务：让客户端发现 pod 并与之通信](05.%20服务：让客户端发现%20pod%20并与之通信.md) 介绍过 Pod 需要发送信号给 Kubernetes 通知它自己已经准备好了。 Pod 在准备好之后，它才能变成一个服务端点，否则无法接收任何客户端的连接请求。 `P500`

如果没有指定就绪探测器，那么 Pod 总是被认为准备好了的。当且仅当应用准备好处理进来的请求时，才让就绪探测器返回成功。 `P500`

### 在 Pod 关闭时避免客户端连接断开 `P501`

#### 了解 Pod 删除时发生的一连串事件 `P501`

当 API 服务器接收到删除 Pod 的请求之后，它首先修改了 etcd 中的状态并把删除事件通知给观察者，其中两个观察者就是 Kubelet 和端点控制器 (Endpoint Controller) 。 `P501`

![图 17.7 Pod 删除时发生的一连串事件](img/chapter17/图%2017.7%20Pod%20删除时发生的一连串事件.png)

移除 iptables 规则对已存在的连接没有影响，已连接到 Pod 的客户端仍然可以通过这些连接向 Pod 发送额外的请求。 `P502`

![图 17.8 Pod 删除时事件发生的时间线](img/chapter17/图%2017.8%20Pod%20删除时事件发生的时间线.png)

观察者是并行响应事件的，并且最有可能的是，关闭 Pod 中应用进程所消耗的事件比完成 iptables 规则更新所需事件稍短。这样 Pod 仍然可以接收客户端请求，但应用已停止接收请求，导致连接被拒绝。 `P502`

#### 解决问题 `P503`

你或许会想到通过添加就绪探测器来解决问题，但这和端点控制器所做的事情没有太大差别。假设你在 Pod 接收到 `SIGTERM` 信号的时候就让就绪探测器开始失败，那么在就绪探测器持续失败一段时间后，才会让 kube-proxy 更新 iptables 规则。而端点控制器在最开始就可以去让 kube-proxy 更新 iptables 规则。 `P503`

合适理想的解决方案是 Pod 在接收到终止信号后仍然保持接收连接直到所有的 kube-proxy 完成了 iptables 规则的更新。实际情况中我们无法轻易得知所有 kube-proxy 是否都完成了 iptables 规则更新，因此可以等待几秒钟，这足以在大部分场景下够用，能极大提升用户体验。 `P504`

妥善关闭一个应用应该包括如下步骤： `P504`

- 等待几秒钟（可以使用 `preStop` 钩子与应用解耦），然后停止接收新的连接
- 关闭所有没有请求过来的长连接
- 等待所有的请求完成
- 完全关闭应用

![图 17.9 在接收到终止信号后妥善的处理已存在和建立的连接](img/chapter17/图%2017.9%20在接收到终止信号后妥善的处理已存在和建立的连接.png)

## 让应用在 Kubernetes 中方便运行和管理 `P505`

### 合理给镜像打标签，正确使用 ImagePullPolicy `P506`

必须使用能够指明具体版本的标签而不是 `latest` ，不同的版本尽量不要使用相同的标签，这样即使 Pod 被扩容/重新调度了，也能保证新旧 Pod 使用相同的镜像。这种情况下的 `Pod.spec.containers.imagePullPolicy` 默认被设置为 `IfNotPresent` ；如果标签是 `latest` ，那么默认被设置为 `Always` 。 `P506`

### 使用多维度而不是单维度的标签 `P506`

确保给每个资源都添加了多个标签，这样就可以通过不同的纬度来选择它们了。 `P506`

- 资源所属的应用/微服务的名称
- 应用层级（前端、后端等）
- 运行环境（开发、测试、预发布、生产等）
- 版本号
- 发布类型（稳定版、金丝雀、蓝绿等）
- 分片（带分片的系统）

### 通过注解描述每个资源 `P506`

资源至少应该包括一个描述资源的注解和一个描述资源负责人的注解。 `P506`

在微服务框架中， Pod 应该包含一个注解来描述该 Pod 依赖的其他服务的名称。其他的注解可以包含构建和版本信息，以及其他工具或者图形界面会使用到的元信息（图标名称等）。 `P507`

### 给进程终止提供更多的信息 `P507`

把所有必须的调试信息都写到日志文件中。 `P507`

可以使用 Kubernetes 的一个特性，该特性可以在 Pod 状态中显示出容器终止的原因。让容器中的进程向容器的文件系统中指定文件写入一个终止消息，这个文件的内容会在容器终止（正常结束或者崩溃终止）后被 Kubelet 读取，然后显示在 `kubectl describe pod` 中。这个文件默认路径是 `/dev/termination-log` ，可以通过 `Pod.spec.containers.terminationMessagePath` 自定义。 `P507`

**注意**：可以将 `Pod.spec.containers.terminationMessagePolicy` 设置为 `FallbackToLogsOnError` （默认是 `File` ，仅从指定文件中获取），这样如果没有向指定的文件写入消息的话，那么就会获取日志的最后内容（最大 2MB 或者 80 行） `P508`

### 处理应用日志 `P508`

`kubectl logs <log> --previous`: 查看容器日志，包括之前容器的日志

#### 使用集中式日志记录 `P509`

使用一个集中式的面向集群的日志解决方案，可以让你所有的日志都被收集并且（永久）存储在一个中心化的位置。这样可以查看历史日志，分析趋势。 `P509`

你或许已经听过由 ElasticSearch, Logstash 和 Kibana 组成的 ELK ，一个稍微更改的变种是 EFK ，其中 Logstash 被 Fluentd 替换了。 `P509`

当使用 EFK 作为集中式日志记录的时候，每个 Kubernetes 集群节点都会运行一个 Fluentd 的代理（通过使用 DaemonSet 作为 Pod 来部署），这个代理负责从容器搜集日志，给日志打上和 Pod 相关的信息，然后把它们发给 ElasticSearch ，然后由 ElasticSearch 存储它们。这些日志可以通过 Kibana 在 Web 浏览器中查看和分析。 `P509`

![图 17.10 使用 EFK 的集中式日志记录](img/chapter17/图%2017.10%20使用%20EFK%20的集中式日志记录.png)

#### 处理多行日志输出 `P510`

Fluentd 代理将日志文件的每一行当作一个条目存储在 ElasticSearch 数据存储中。当日志输出跨越多行时，就会以不同条目存储在集中式的日志系统中。有两种方法可以解决： `P510`

- 让应用日志输出 JSON 格式的内容而非纯文本。这样多行日志可以作为一个条目存储，但是通过 `kubectl logs` 查看日志时却不太友好
- 输出到终端的日志仍是用户可读的日志，而写入日志文件供 Fluentd 处理的日志是 JSON 格式。这就要求在节点级别合理地配置 Fluentd 代理或者给每一个 Pod 增加一个轻量级的日志记录容器
